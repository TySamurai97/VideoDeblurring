{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as gb\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_utils\n",
    "from losses import adversarial_loss, generator_loss\n",
    "from model import generator_model, discriminator_model, generator_containing_discriminator\n",
    "\n",
    "g_loss_y = []\n",
    "d_loss_y = []\n",
    "g_on_d_loss_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, epoch_num):\n",
    "    # Note the x(blur) in the second, the y(full) in the first\n",
    "    y_train, x_train = data_utils.load_data(data_type='train')\n",
    "\n",
    "    # GAN\n",
    "    g = generator_model()\n",
    "    d = discriminator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "\n",
    "    # compile the models, use default optimizer parameters\n",
    "    # generator use adversarial loss\n",
    "\n",
    "\n",
    "    g.load_weights('C:/Users/tanay/Desktop/VideoDeblurring-MinorCOPECS/weight/generator_weights.h5')\n",
    "    g.compile(optimizer='adam', loss=generator_loss)\n",
    "    # discriminator use binary cross entropy loss\n",
    "    d.load_weights('C:/Users/tanay/Desktop/VideoDeblurring-MinorCOPECS/weight/discriminator_weights.h5')\n",
    "    d.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "\n",
    "    # adversarial net use adversarial loss\n",
    "    d_on_g.compile(optimizer='adam', loss=adversarial_loss)\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        print('epoch: ', epoch + 1, '/', epoch_num)\n",
    "        print('batches: ', int(x_train.shape[0] / batch_size))\n",
    "\n",
    "        for index in range(int(x_train.shape[0] / batch_size)):\n",
    "            # select a batch data\n",
    "            image_blur_batch = x_train[index * batch_size:(index + 1) * batch_size]\n",
    "            image_full_batch = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "            generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
    "            # output generated images for each 30 iters\n",
    "#             if (index % 30 == 0) and (index != 0):\n",
    "#                 data_utils.generate_image(image_full_batch, image_blur_batch, generated_images,\n",
    "#                                           'result/interim/', epoch, index)\n",
    "\n",
    "            # concatenate the full and generated images,\n",
    "            # the full images at top, the generated images at bottom\n",
    "            x = np.concatenate((image_full_batch, generated_images))\n",
    "\n",
    "            # generate labels for the full and generated images\n",
    "            y = [1] * batch_size + [0] * batch_size\n",
    "\n",
    "            # train discriminator\n",
    "            d_loss = d.train_on_batch(x, y)\n",
    "            d_loss_y.append(d_loss)\n",
    "            print('batch %d d_loss : %f' % (index + 1, d_loss))\n",
    "\n",
    "            # let discriminator can't be trained\n",
    "            d.trainable = False\n",
    "\n",
    "            # train adversarial net\n",
    "            d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [1] * batch_size)\n",
    "            g_on_d_loss_y.append(d_on_g_loss)\n",
    "            print('batch %d d_on_g_loss : %f' % (index + 1, d_on_g_loss))\n",
    "\n",
    "            # train generator\n",
    "            g_loss = g.train_on_batch(image_blur_batch, image_full_batch)\n",
    "            g_loss_y.append(g_loss)\n",
    "            print('batch %d g_loss : %f' % (index + 1, g_loss))\n",
    "\n",
    "            # let discriminator can be trained\n",
    "            d.trainable = True\n",
    "\n",
    "            # output weights for generator and discriminator each 30 iters\n",
    "        g.save_weights('C:/Users/tanay/Desktop/VideoDeblurring-MinorCOPECS/weight/generator_weights.h5', True)\n",
    "        d.save_weights('C:/Users/tanay/Desktop/VideoDeblurring-MinorCOPECS/weight/discriminator_weights.h5', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(batch_size):\n",
    "    # Note the x(blur) in the second, the y(full) in the first\n",
    "    y_test, x_test = data_utils.load_data(data_type='test')\n",
    "    g = generator_model()\n",
    "    g.load_weights('C:/Users/tanay/Desktop/VideoDeblurring-MinorCOPECS/weight/generator_weights.h5')\n",
    "    generated_images = g.predict(x=x_test, batch_size=batch_size)\n",
    "    data_utils.generate_image(y_test, x_test, generated_images, 'C:/Users/tanay/Desktop/VideoDeblurring-MinorCOPECS/result/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results():\n",
    "    plt.plot([i for i in range(len(d_loss_y))], d_loss_y,'g-')\n",
    "    plt.ylabel('d loss')\n",
    "    plt.show()\n",
    "    plt.plot([i for i in range(len(g_loss_y))], g_loss_y,'r-')\n",
    "    plt.ylabel('g loss')\n",
    "    plt.show()\n",
    "    plt.plot([i for i in range(len(g_on_d_loss_y))], g_on_d_loss_y,'b-')\n",
    "    plt.ylabel('g on d loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pictures(batch_size):\n",
    "    data_path = 'data/test/*.jpeg'\n",
    "    images_path = gb.glob(data_path)\n",
    "    data_blur = []\n",
    "    for image_path in images_path:\n",
    "        image_blur = Image.open(image_path)\n",
    "        data_blur.append(np.array(image_blur))\n",
    "\n",
    "    data_blur = np.array(data_blur).astype(np.float32)\n",
    "    data_blur = data_utils.normalization(data_blur)\n",
    "\n",
    "    g = generator_model()\n",
    "    g.load_weights('weight/generator_weights.h5')\n",
    "    generated_images = g.predict(x=data_blur, batch_size=batch_size)\n",
    "    generated = generated_images * 127.5 + 127.5\n",
    "    for i in range(generated.shape[0]):\n",
    "        image_generated = generated[i, :, :, :]\n",
    "        Image.fromarray(image_generated.astype(np.uint8)).save('result/test/' + str(i) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     train(batch_size=4, epoch_num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "#     plot_results()\n",
    "    test(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
